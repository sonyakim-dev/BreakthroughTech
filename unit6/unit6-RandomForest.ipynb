{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, will you will see how to train two gradient boosted decision trees and compare their performances. \n",
    "\n",
    "\n",
    "**<font color='red'>Note: Some of the code cells in this notebook may take a while to run.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages. Run the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the scikit-learn `RandomForestClassifier`, the `train_test_split()` function for splitting the data into training and test sets, and the functions `roc_curve` and `auc` to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build Your DataFrame and Define Your ML Problem\n",
    "\n",
    "We will work with the \"cell2celltrain\" data set. This data set is already preprocessed, with the proper formatting, outliers, and missing values taken care of, and all numerical columns scaled to the [0, 1] interval. One-hot encoding has been performed on all categorical columns. Run the cell below to load the data set and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.getcwd(), \"data_RF\", \"cell2celltrain.csv\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Label\n",
    "\n",
    "This is a binary classification problem in which we will predict customer churn. The label is the `Churn` column.\n",
    "\n",
    "#### Identify Features\n",
    "\n",
    "Our features will be all of the remaining columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Labeled Examples from the Data Set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn'] \n",
    "X = df.drop(columns = 'Churn', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Two Random Forest Classifiers\n",
    "\n",
    "<p>The random forest (RF) algorithm is probably the most well known and utilized implementation of the bagging technique. A RF is an ensemble of decision trees, where both bagging and random feature selection are used to reduce the variance of the forest.\n",
    "    \n",
    "We will use the scikit-learn's `RandomForestClassifier`. Please refer to the online [documentation](http://scikit-learn.org/stable/modules/ensemble.html) for a brief overview of scikit-learn's ensemble methods.\n",
    "\n",
    "We will not perform any special hyperparameter optimization, but will instead compare two Random Forest models that differ only in the number of estimators (decision trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, build and train two random forest models, one with 20 estimators and one with 100 estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-rf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "print('Begin Random Forest Implementation...')\n",
    "# 1. Create the RandomForestClassifier model object below and assign to variable 'rf_20_model'\n",
    "rf_20_model = RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_20_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions on the test data using the predict_proba() method and assign the \n",
    "# result to a list named 'rf_20_predictions' \n",
    "rf_20_preds = rf_20_model.predict_proba(X_test)\n",
    "rf_20_predictions = list(rf_20_preds[:, -1])\n",
    "\n",
    "# 4. Create the RandomForestClassifier model object below and assign to variable \n",
    "# 'rf_100_model'\n",
    "rf_100_model = RandomForestClassifier(criterion='entropy', n_estimators=100)\n",
    "\n",
    "# 5. Fit the model to the training data \n",
    "rf_100_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions on the test data using the predict_proba() method and \n",
    "# assign the result to a list named 'rf_100_predictions' \n",
    "rf_100_preds = rf_100_model.predict_proba(X_test)\n",
    "rf_100_predictions = list(rf_100_preds[:, -1])\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Performance Using ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot two ROC curves for the two RF classifiers on the same graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-roc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "print('Computing ROC Curve...')\n",
    "\n",
    "# Use roc_curve to record fpr and tpr for rf_20_model\n",
    "fpr_20, tpr_20, thresholds_20 = roc_curve(y_test, rf_20_predictions)\n",
    "\n",
    "# Use roc_curve to record fpr and tpr for rf_100_model\n",
    "fpr_100, tpr_100, thresholds_100 = roc_curve(y_test, rf_100_predictions)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below plots the ROC curves for both models. Run the code cell and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plotting ROC Curve...')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "sns.lineplot(x=fpr_20, y=tpr_20, marker = 'o')\n",
    "sns.lineplot(x=fpr_100, y=tpr_100, marker = 'o')\n",
    "\n",
    "plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.legend(['RF with 20 estimators', 'RF with 100 estimators'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that with the random forest model that was fit using a larger number of estimators performs better. Let's quantify this difference in performance using AUC. The code cell below uses the `auc()` function to compute the areas under each of the receiver operating characteristic (ROC) curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-auc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# AUC for rf_20_model\n",
    "auc_20 = auc(fpr_20, tpr_20)\n",
    "print(\"AUC of the RF model with 20 estimators is {:.3f}\".format(auc_20))\n",
    "\n",
    "# AUC for rf_100_model\n",
    "auc_100 = auc(fpr_100, tpr_100)\n",
    "print(\"AUC of the RF model with 100 estimators is {:.3f}\".format(auc_100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
